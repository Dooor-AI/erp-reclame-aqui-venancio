{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Gemini Integration Test\n",
    "\n",
    "This notebook tests the Gemini API integration for the Venâncio RPA project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded: AIzaSyAhlA51XpZ_rshb...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "print(f\"API Key loaded: {api_key[:20]}...\" if api_key else \"No API key found!\")\n",
    "\n",
    "# Configure Gemini\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. List Available Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Gemini models that support generateContent:\n",
      "======================================================================\n",
      "- models/gemini-2.5-pro-preview-03-25\n",
      "- models/gemini-2.5-flash-preview-05-20\n",
      "- models/gemini-2.5-flash\n",
      "- models/gemini-2.5-flash-lite-preview-06-17\n",
      "- models/gemini-2.5-pro-preview-05-06\n",
      "- models/gemini-2.5-pro-preview-06-05\n",
      "- models/gemini-2.5-pro\n",
      "- models/gemini-2.0-flash-exp\n",
      "- models/gemini-2.0-flash\n",
      "- models/gemini-2.0-flash-001\n",
      "- models/gemini-2.0-flash-exp-image-generation\n",
      "- models/gemini-2.0-flash-lite-001\n",
      "- models/gemini-2.0-flash-lite\n",
      "- models/gemini-2.0-flash-lite-preview-02-05\n",
      "- models/gemini-2.0-flash-lite-preview\n",
      "- models/gemini-2.0-pro-exp\n",
      "- models/gemini-2.0-pro-exp-02-05\n",
      "- models/gemini-exp-1206\n",
      "- models/gemini-2.0-flash-thinking-exp-01-21\n",
      "- models/gemini-2.0-flash-thinking-exp\n",
      "- models/gemini-2.0-flash-thinking-exp-1219\n",
      "- models/gemini-2.5-flash-preview-tts\n",
      "- models/gemini-2.5-pro-preview-tts\n",
      "- models/learnlm-2.0-flash-experimental\n",
      "- models/gemma-3-1b-it\n",
      "- models/gemma-3-4b-it\n",
      "- models/gemma-3-12b-it\n",
      "- models/gemma-3-27b-it\n",
      "- models/gemma-3n-e4b-it\n",
      "- models/gemma-3n-e2b-it\n",
      "- models/gemini-flash-latest\n",
      "- models/gemini-flash-lite-latest\n",
      "- models/gemini-pro-latest\n",
      "- models/gemini-2.5-flash-lite\n",
      "- models/gemini-2.5-flash-image-preview\n",
      "- models/gemini-2.5-flash-image\n",
      "- models/gemini-2.5-flash-preview-09-2025\n",
      "- models/gemini-2.5-flash-lite-preview-09-2025\n",
      "- models/gemini-robotics-er-1.5-preview\n",
      "- models/gemini-2.5-computer-use-preview-10-2025\n"
     ]
    }
   ],
   "source": [
    "# List all available models\n",
    "print(\"Available Gemini models that support generateContent:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model in genai.list_models():\n",
    "    if 'generateContent' in model.supported_generation_methods:\n",
    "        print(f\"- {model.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Gemini Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "print(\"Model initialized: gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test 1: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Sentiment Analysis\n",
      "======================================================================\n",
      "Text: Produto péssimo, quebrou em 2 dias! Nunca mais compro aqui.\n",
      "\n",
      "Response:\n",
      "```json\n",
      "{\n",
      "  \"sentiment\": \"Negativo\",\n",
      "  \"score\": 1,\n",
      "  \"reasoning\": \"A frase contém termos fortemente negativos como 'péssimo' e descreve um evento de falha crítica ('quebrou em 2 dias'). A expressão 'Nunca mais compro aqui' reforça a insatisfação extrema e a intenção de não repetir a compra, indicando um sentimento de rejeição e frustração muito alto.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Test sentiment analysis\n",
    "prompt = \"\"\"Analise o sentimento desta frase e retorne JSON:\n",
    "{\n",
    "  \"sentiment\": \"Negativo/Neutro/Positivo\",\n",
    "  \"score\": 0-10,\n",
    "  \"reasoning\": \"explicação\"\n",
    "}\n",
    "\n",
    "Responda APENAS com o JSON.\"\"\"\n",
    "\n",
    "text = \"Produto péssimo, quebrou em 2 dias! Nunca mais compro aqui.\"\n",
    "\n",
    "print(\"Test 1: Sentiment Analysis\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Text: {text}\")\n",
    "print()\n",
    "\n",
    "full_prompt = f\"{prompt}\\n\\nTexto:\\n{text}\"\n",
    "response = model.generate_content(full_prompt)\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test 2: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test classification\n",
    "prompt = \"\"\"Classifique esta reclamação em categorias:\n",
    "- produto\n",
    "- atendimento\n",
    "- entrega\n",
    "- preco\n",
    "- outros\n",
    "\n",
    "Retorne JSON:\n",
    "{\n",
    "  \"categories\": [\"cat1\", \"cat2\"],\n",
    "  \"primary_category\": \"principal\"\n",
    "}\n",
    "\n",
    "Responda APENAS com o JSON.\"\"\"\n",
    "\n",
    "text = \"Comprei uma geladeira e ela chegou com defeito. O atendimento ao cliente também foi horrível.\"\n",
    "\n",
    "print(\"Test 2: Classification\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Text: {text}\")\n",
    "print()\n",
    "\n",
    "full_prompt = f\"{prompt}\\n\\nTexto:\\n{text}\"\n",
    "response = model.generate_content(full_prompt)\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test 3: Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test entity extraction\n",
    "prompt = \"\"\"Extraia entidades desta reclamação e retorne JSON:\n",
    "{\n",
    "  \"produto\": \"nome do produto\",\n",
    "  \"loja\": \"nome da loja\",\n",
    "  \"funcionario\": \"nome do funcionário ou null\"\n",
    "}\n",
    "\n",
    "Responda APENAS com o JSON.\"\"\"\n",
    "\n",
    "text = \"Comprei um fogão 5 bocas na loja do Shopping Center. O atendente Carlos foi muito rude.\"\n",
    "\n",
    "print(\"Test 3: Entity Extraction\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Text: {text}\")\n",
    "print()\n",
    "\n",
    "full_prompt = f\"{prompt}\\n\\nTexto:\\n{text}\"\n",
    "response = model.generate_content(full_prompt)\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test with Real Complaint Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a realistic complaint\n",
    "complaint = \"\"\"Comprei um fogão de 5 bocas há 3 meses e já apresentou defeito. \n",
    "Liguei no atendimento 4 vezes e ninguém resolve meu problema. \n",
    "A atendente Maria disse que ia enviar um técnico mas já faz 2 semanas e nada. \n",
    "Estou muito insatisfeito e vou processar a loja se não resolverem!\"\"\"\n",
    "\n",
    "print(\"Test with Real Complaint\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Complaint: {complaint}\")\n",
    "print()\n",
    "\n",
    "# Combined analysis\n",
    "combined_prompt = \"\"\"Analise esta reclamação e retorne um JSON completo com:\n",
    "{\n",
    "  \"sentiment\": {\n",
    "    \"label\": \"Negativo/Neutro/Positivo\",\n",
    "    \"score\": 0-10\n",
    "  },\n",
    "  \"categories\": [\"produto\", \"atendimento\", etc],\n",
    "  \"primary_category\": \"principal\",\n",
    "  \"entities\": {\n",
    "    \"produto\": \"nome do produto ou null\",\n",
    "    \"loja\": \"nome da loja ou null\",\n",
    "    \"funcionario\": \"nome do funcionário ou null\"\n",
    "  },\n",
    "  \"urgency_indicators\": [\"lista de palavras que indicam urgência\"]\n",
    "}\n",
    "\n",
    "Responda APENAS com o JSON.\"\"\"\n",
    "\n",
    "full_prompt = f\"{combined_prompt}\\n\\nReclamação:\\n{complaint}\"\n",
    "response = model.generate_content(full_prompt)\n",
    "\n",
    "print(\"Combined Analysis Response:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Parse JSON Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Clean and parse the response\n",
    "result_text = response.text.strip()\n",
    "\n",
    "# Remove markdown formatting if present\n",
    "if result_text.startswith(\"```json\"):\n",
    "    result_text = result_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "elif result_text.startswith(\"```\"):\n",
    "    result_text = result_text.replace(\"```\", \"\").strip()\n",
    "\n",
    "# Parse JSON\n",
    "try:\n",
    "    parsed = json.loads(result_text)\n",
    "    print(\"Parsed JSON:\")\n",
    "    print(json.dumps(parsed, indent=2, ensure_ascii=False))\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON parsing error: {e}\")\n",
    "    print(f\"Raw text: {result_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "✅ **Tests Completed:**\n",
    "- Sentiment Analysis\n",
    "- Classification\n",
    "- Entity Extraction\n",
    "- Combined Analysis\n",
    "- JSON Parsing\n",
    "\n",
    "**Next Steps:**\n",
    "1. Run full validation: `python backend/validate_analysis.py`\n",
    "2. Test API endpoints: `uvicorn backend.app.main:app --reload`\n",
    "3. Check backend integration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
