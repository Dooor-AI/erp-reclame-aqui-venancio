# ğŸ“‹ Order for Chat B - Round 1

**From:** Commander
**To:** Chat B
**Date:** 2025-11-17
**Priority:** ğŸ”´ Critical
**Estimated Duration:** 8-10 hours (Dias 2-3)

---

## ğŸ¯ Mission

Implementar anÃ¡lise de sentimento e classificaÃ§Ã£o automÃ¡tica de reclamaÃ§Ãµes usando Anthropic Claude API.

---

## ğŸ“‹ Background

As reclamaÃ§Ãµes coletadas pelo Chat A precisam ser analisadas para:
- Identificar sentimento (Negativo/Neutro/Positivo)
- Classificar por tipo (produto, atendimento, entrega, preÃ§o, outros)
- Extrair entidades (produto mencionado, loja, funcionÃ¡rio)
- Calcular score de urgÃªncia (0-10)

**Dependencies:**
- âš ï¸ **Chat A deve estar em 50%** (dados disponÃ­veis para testar)
- âœ… Acesso Ã  API do Claude (verificar crÃ©ditos)

---

## ğŸš€ Your Tasks

### Task 1: IntegraÃ§Ã£o com API Claude (2h)

**Steps:**

1. Adicionar ao `requirements.txt`:
```
anthropic==0.8.1
```

2. Criar `app/ai/claude_client.py`:
```python
from anthropic import Anthropic
from app.core.config import settings
import logging

logger = logging.getLogger(__name__)

class ClaudeClient:
    def __init__(self):
        self.client = Anthropic(api_key=settings.ANTHROPIC_API_KEY)
        self.model = "claude-3-5-sonnet-20241022"

    async def analyze_text(self, prompt: str, text: str) -> str:
        """AnÃ¡lise de texto genÃ©rica"""
        try:
            message = self.client.messages.create(
                model=self.model,
                max_tokens=1024,
                messages=[
                    {
                        "role": "user",
                        "content": f"{prompt}\n\nTexto:\n{text}"
                    }
                ]
            )
            return message.content[0].text
        except Exception as e:
            logger.error(f"Erro na API Claude: {e}")
            raise
```

3. Adicionar no `.env`:
```
ANTHROPIC_API_KEY=sk-ant-...
```

4. Testar conexÃ£o com API

**Expected Result:**
- âœ… Claude API integrada
- âœ… Wrapper funcional
- âœ… Tratamento de erros

---

### Task 2: AnÃ¡lise de Sentimento (2h)

**Criar:** `app/ai/sentiment_analyzer.py`

```python
import json
from app.ai.claude_client import ClaudeClient
from typing import Tuple

SENTIMENT_PROMPT = """Analise o sentimento da seguinte reclamaÃ§Ã£o de cliente.

Retorne um JSON com:
- sentiment: "Negativo", "Neutro" ou "Positivo"
- score: nÃºmero de 0 a 10 (0=muito negativo, 5=neutro, 10=muito positivo)
- reasoning: breve justificativa (1 frase)

Responda APENAS com o JSON, sem texto adicional."""

class SentimentAnalyzer:
    def __init__(self):
        self.client = ClaudeClient()

    async def analyze(self, text: str) -> dict:
        """Analisar sentimento"""
        response = await self.client.analyze_text(SENTIMENT_PROMPT, text)

        # Parse JSON
        result = json.loads(response)

        return {
            'sentiment': result['sentiment'],
            'sentiment_score': result['score'],
            'reasoning': result.get('reasoning', '')
        }
```

**ValidaÃ§Ã£o:**
- Testar com 10-20 reclamaÃ§Ãµes
- Validar manualmente
- AcurÃ¡cia >= 80%

**Expected Result:**
- âœ… AnÃ¡lise de sentimento funcionando
- âœ… Formato JSON validado
- âœ… 80%+ acurÃ¡cia

---

### Task 3: ClassificaÃ§Ã£o de Tipo (2h)

**Criar:** `app/ai/classifier.py`

```python
CLASSIFICATION_PROMPT = """Classifique a reclamaÃ§Ã£o abaixo nas seguintes categorias:
- produto: problema com produto (defeito, qualidade, etc)
- atendimento: problema com atendimento (rude, ineficiente, etc)
- entrega: problema com entrega (atraso, extravio, etc)
- preco: problema com preÃ§o/cobranÃ§a
- outros: outros tipos de problemas

Pode haver mÃºltiplas categorias. Retorne JSON:
{
  "categories": ["categoria1", "categoria2"],
  "primary_category": "categoria_principal",
  "confidence": 0.9
}

Responda APENAS com o JSON."""

class Classifier:
    def __init__(self):
        self.client = ClaudeClient()

    async def classify(self, text: str) -> dict:
        response = await self.client.analyze_text(CLASSIFICATION_PROMPT, text)
        result = json.loads(response)

        return {
            'categories': result['categories'],
            'primary_category': result['primary_category'],
            'confidence': result.get('confidence', 0.0)
        }
```

**Expected Result:**
- âœ… ClassificaÃ§Ã£o funcionando
- âœ… MÃºltiplas categorias suportadas
- âœ… ValidaÃ§Ã£o manual OK

---

### Task 4: ExtraÃ§Ã£o de Entidades (2h)

**Criar:** `app/ai/entity_extractor.py`

```python
ENTITY_PROMPT = """Extraia as seguintes entidades da reclamaÃ§Ã£o:
- produto: nome do produto mencionado
- loja: nome da loja/unidade mencionada
- funcionario: nome de funcionÃ¡rio mencionado (se houver)
- outros: outras entidades relevantes

Retorne JSON:
{
  "produto": "nome do produto",
  "loja": "nome da loja",
  "funcionario": null,
  "outros": ["entidade1", "entidade2"]
}

Se nÃ£o encontrar, use null. Responda APENAS com o JSON."""

class EntityExtractor:
    def __init__(self):
        self.client = ClaudeClient()

    async def extract(self, text: str) -> dict:
        response = await self.client.analyze_text(ENTITY_PROMPT, text)
        return json.loads(response)
```

**Expected Result:**
- âœ… ExtraÃ§Ã£o de entidades funcionando
- âœ… Estrutura JSON validada

---

### Task 5: Score de UrgÃªncia (1h)

**Criar:** `app/ai/urgency_scorer.py`

```python
class UrgencyScorer:
    URGENT_KEYWORDS = [
        'processual', 'judicial', 'procon', 'advogado',
        'processo', 'aÃ§Ã£o', 'justiÃ§a', 'urgente',
        'imediato', 'grave', 'sÃ©rio', 'inadmissÃ­vel'
    ]

    def calculate_score(self, text: str, sentiment_score: float) -> float:
        """Calcular urgÃªncia (0-10)"""
        score = 0.0

        # Base: inversÃ£o do sentiment (negativo = urgente)
        score += (10 - sentiment_score) * 0.5

        # Keywords
        text_lower = text.lower()
        keyword_count = sum(1 for kw in self.URGENT_KEYWORDS if kw in text_lower)
        score += min(keyword_count * 1.5, 5.0)

        return min(score, 10.0)
```

**Expected Result:**
- âœ… Score de urgÃªncia calculado
- âœ… Baseado em sentimento + keywords

---

### Task 6: Pipeline Completo + API (1h)

**Criar:** `app/services/analysis_service.py`

```python
from app.ai.sentiment_analyzer import SentimentAnalyzer
from app.ai.classifier import Classifier
from app.ai.entity_extractor import EntityExtractor
from app.ai.urgency_scorer import UrgencyScorer
from app.db.crud import update_complaint_analysis
from sqlalchemy.orm import Session

class AnalysisService:
    def __init__(self):
        self.sentiment_analyzer = SentimentAnalyzer()
        self.classifier = Classifier()
        self.entity_extractor = EntityExtractor()
        self.urgency_scorer = UrgencyScorer()

    async def analyze_complaint(self, db: Session, complaint_id: int):
        """Pipeline completo de anÃ¡lise"""
        complaint = db.query(Complaint).filter(Complaint.id == complaint_id).first()
        if not complaint:
            raise ValueError("Complaint not found")

        text = f"{complaint.title}\n\n{complaint.text}"

        # 1. Sentimento
        sentiment_result = await self.sentiment_analyzer.analyze(text)

        # 2. ClassificaÃ§Ã£o
        classification_result = await self.classifier.classify(text)

        # 3. Entidades
        entities = await self.entity_extractor.extract(text)

        # 4. UrgÃªncia
        urgency = self.urgency_scorer.calculate_score(
            text,
            sentiment_result['sentiment_score']
        )

        # Atualizar banco
        update_complaint_analysis(
            db,
            complaint_id,
            sentiment=sentiment_result['sentiment'],
            sentiment_score=sentiment_result['sentiment_score'],
            classification=classification_result['categories'],
            entities=entities,
            urgency_score=urgency
        )

        return {
            "complaint_id": complaint_id,
            "sentiment": sentiment_result,
            "classification": classification_result,
            "entities": entities,
            "urgency_score": urgency
        }
```

**Criar endpoints** em `app/api/endpoints/analytics.py`:

```python
from fastapi import APIRouter, Depends
from app.services.analysis_service import AnalysisService
from app.core.database import get_db

router = APIRouter(prefix="/analytics", tags=["analytics"])

@router.post("/analyze/{complaint_id}")
async def analyze_complaint(complaint_id: int, db: Session = Depends(get_db)):
    service = AnalysisService()
    result = await service.analyze_complaint(db, complaint_id)
    return result

@router.post("/analyze/batch")
async def analyze_batch(db: Session = Depends(get_db)):
    """Analisar todas as reclamaÃ§Ãµes nÃ£o analisadas"""
    complaints = db.query(Complaint).filter(Complaint.sentiment == None).all()

    service = AnalysisService()
    results = []

    for complaint in complaints:
        try:
            result = await service.analyze_complaint(db, complaint.id)
            results.append(result)
        except Exception as e:
            logger.error(f"Erro ao analisar {complaint.id}: {e}")

    return {"analyzed": len(results), "total": len(complaints)}

@router.get("/stats/sentiment")
async def sentiment_stats(db: Session = Depends(get_db)):
    """EstatÃ­sticas de sentimento"""
    stats = db.query(
        Complaint.sentiment,
        func.count(Complaint.id),
        func.avg(Complaint.sentiment_score)
    ).group_by(Complaint.sentiment).all()

    return {
        "by_sentiment": [
            {"sentiment": s[0], "count": s[1], "avg_score": s[2]}
            for s in stats
        ]
    }

@router.get("/stats/categories")
async def category_stats(db: Session = Depends(get_db)):
    """Top 5 categorias"""
    # Implementar contagem de categorias do JSON
    pass

@router.get("/stats/urgency")
async def urgency_stats(db: Session = Depends(get_db)):
    """ReclamaÃ§Ãµes mais urgentes"""
    urgent = db.query(Complaint).filter(
        Complaint.urgency_score >= 7.0
    ).order_by(Complaint.urgency_score.desc()).limit(10).all()

    return {"urgent_complaints": urgent}
```

**Registrar router** em `main.py`

**Expected Result:**
- âœ… Pipeline completo funcionando
- âœ… Endpoint de anÃ¡lise individual
- âœ… Endpoint de anÃ¡lise em lote
- âœ… Endpoints de estatÃ­sticas

---

## ğŸ“ Deliverables

1. **`answer_chat_B_1.md`** - Your results
2. **Backend code** - All AI modules and endpoints
3. **Sample analysis** - 10-15 reclamaÃ§Ãµes analisadas com validaÃ§Ã£o manual

**Answer File Must Include:**

- Status (âœ… Complete / ğŸ”„ In Progress / âš ï¸ Blocked)
- Summary of what was done
- Analysis accuracy validation (>=80%)
- Number of complaints analyzed
- API endpoints implemented
- Sample results
- Issues encountered
- Time tracking summary

---

## â° Time Tracking

```markdown
# Chat B - Round 1 - Time Tracking

**Started:** [HH:MM]
**Estimated Duration:** 8-10 hours
**Expected Completion:** [HH:MM] (Day 3 EOD)
**Timeout Threshold:** [HH:MM] (ETA + 10%)

| Task | Estimated | Actual | Status |
|------|-----------|--------|--------|
| Task 1: Claude API | 2h | - | â³ |
| Task 2: Sentiment | 2h | - | â³ |
| Task 3: Classification | 2h | - | â³ |
| Task 4: Entities | 2h | - | â³ |
| Task 5: Urgency | 1h | - | â³ |
| Task 6: Pipeline | 1h | - | â³ |
```

---

## ğŸ¯ Success Criteria

- âœ… Claude API integrada e funcionando
- âœ… AnÃ¡lise de sentimento com 80%+ acurÃ¡cia (validaÃ§Ã£o manual)
- âœ… ClassificaÃ§Ã£o por categorias funcionando
- âœ… ExtraÃ§Ã£o de entidades implementada
- âœ… Score de urgÃªncia calculado
- âœ… Pipeline completo rodando
- âœ… Endpoints de analytics criados
- âœ… DocumentaÃ§Ã£o dos prompts

---

## ğŸ“ Questions?

If you encounter:

- **Claude API errors** â†’ Check API key, rate limits, create alert
- **JSON parsing issues** â†’ Adjust prompts, add validation
- **Low accuracy (<80%)** â†’ Refine prompts, test more examples
- **Rate limiting** â†’ Implement caching, reduce calls
- **Chat A not ready** â†’ Create `question_B_to_A_1.md` or wait for checkpoint

---

## ğŸ”„ Related Tasks

- **Chat A** provides the data you need
- **Chat C** (Response Generator) depends on your analysis
- **Chat D** (Dashboard) will display your statistics
- **Chat E** will document your AI prompts

**At 100% completion**, create `coordination/alerts/checkpoint_B_100.md` to notify Chat C can start.

---

**Start when Chat A reaches 50%! Good luck! ğŸš€**

**Remember:** Your analysis quality determines response quality. Take time to validate!
